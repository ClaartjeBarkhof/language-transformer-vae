{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x += 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1021 10:21:24.447685 4487536064 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "E1021 10:21:33.150783 4487536064 ultratb.py:152] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "I1021 10:21:33.244575 4487536064 ultratb.py:1185] \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n",
      "E1021 10:21:33.266617 4487536064 ultratb.py:152] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "I1021 10:21:33.272753 4487536064 ultratb.py:1185] \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n",
      "E1021 10:21:33.311992 4487536064 ultratb.py:152] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "I1021 10:21:33.318783 4487536064 ultratb.py:1185] \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-71025d3c4828>\", line 1, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelWithLMHead\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/__init__.py\", line 23, in <module>\n",
      "    from .benchmark_utils import (\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/benchmark_utils.py\", line 14, in <module>\n",
      "    from .file_utils import is_tf_available, is_torch_available\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/file_utils.py\", line 53, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 101, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 947, in _find_and_load_unlocked\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/__init__.py\", line 64, in <module>\n",
      "    from tensorflow.core.framework.graph_pb2 import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/node_def_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python.eager import context as _context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/protobuf/config_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import cost_graph_pb2 as tensorflow_dot_core_dot_framework_dot_cost__graph__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/cost_graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-71025d3c4828>\", line 1, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelWithLMHead\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/__init__.py\", line 23, in <module>\n",
      "    from .benchmark_utils import (\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/benchmark_utils.py\", line 14, in <module>\n",
      "    from .file_utils import is_tf_available, is_torch_available\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/file_utils.py\", line 53, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 101, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 947, in _find_and_load_unlocked\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/__init__.py\", line 64, in <module>\n",
      "    from tensorflow.core.framework.graph_pb2 import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/node_def_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python.eager import context as _context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/protobuf/config_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import cost_graph_pb2 as tensorflow_dot_core_dot_framework_dot_cost__graph__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/cost_graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-71025d3c4828>\", line 1, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelWithLMHead\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/__init__.py\", line 23, in <module>\n",
      "    from .benchmark_utils import (\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/benchmark_utils.py\", line 14, in <module>\n",
      "    from .file_utils import is_tf_available, is_torch_available\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/transformers/file_utils.py\", line 53, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 101, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 947, in _find_and_load_unlocked\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/__init__.py\", line 64, in <module>\n",
      "    from tensorflow.core.framework.graph_pb2 import *\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/node_def_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/_api/v2/audio/__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_audio_ops.py\", line 10, in <module>\n",
      "    from tensorflow.python.eager import context as _context\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/protobuf/config_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import cost_graph_pb2 as tensorflow_dot_core_dot_framework_dot_cost__graph__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/cost_graph_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/Users/claartje/miniconda3/lib/python3.6/site-packages/tensorflow_core/core/framework/tensor_shape_pb2.py\", line 23, in <module>\n",
      "    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tBq\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "TypeError: __new__() got an unexpected keyword argument 'serialized_options'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thomasdehaene/gpt2-large-dutch-finetune-oscar-10m-3epoch\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"thomasdehaene/gpt2-large-dutch-finetune-oscar-10m-3epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 14:05:56.439916 4676832704 filelock.py:274] Lock 140728789747752 acquired on /Users/claartje/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c30bc21e61434bb148a4d467ae8dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=760.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 14:05:56.904492 4676832704 filelock.py:318] Lock 140728789747752 released on /Users/claartje/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claartje/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "I1016 14:05:57.332174 4676832704 filelock.py:274] Lock 140727482736256 acquired on /Users/claartje/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1ba92986f2488f8e69f296526b8235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=798011.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 14:05:58.366622 4676832704 filelock.py:318] Lock 140727482736256 released on /Users/claartje/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claartje/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/transformers/modeling_auto.py:785: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "I1016 14:05:58.984509 4676832704 filelock.py:274] Lock 140722326870560 acquired on /Users/claartje/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769ad6bb325a4ebbadeb7b7a454decae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=467042463.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 14:06:39.557795 4676832704 filelock.py:318] Lock 140722326870560 released on /Users/claartje/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer_xlnet = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "model_xlnet = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters XLNet 116750336\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XLNetTokenizer' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6b0f59b14cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of parameters XLNet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_n_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xlnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of tokens in vocabulary XLNet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_xlnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'XLNetTokenizer' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters XLNet\", get_n_params(model_xlnet))\n",
    "print(\"Number of tokens in vocabulary XLNet\", len(tokenizer_xlnet.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('transformer',\n",
       "               XLNetModel(\n",
       "                 (word_embedding): Embedding(32000, 768)\n",
       "                 (layer): ModuleList(\n",
       "                   (0): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (1): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (2): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (3): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (4): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (5): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (6): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (7): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (8): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (9): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (10): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                   (11): XLNetLayer(\n",
       "                     (rel_attn): XLNetRelativeAttention(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (ff): XLNetFeedForward(\n",
       "                       (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                       (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                       (dropout): Dropout(p=0.1, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0.1, inplace=False)\n",
       "                   )\n",
       "                 )\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )),\n",
       "              ('lm_loss',\n",
       "               Linear(in_features=768, out_features=32000, bias=True))]),\n",
       " 'config': XLNetConfig {\n",
       "   \"architectures\": [\n",
       "     \"XLNetLMHeadModel\"\n",
       "   ],\n",
       "   \"attn_type\": \"bi\",\n",
       "   \"bi_data\": false,\n",
       "   \"bos_token_id\": 1,\n",
       "   \"clamp_len\": -1,\n",
       "   \"d_head\": 64,\n",
       "   \"d_inner\": 3072,\n",
       "   \"d_model\": 768,\n",
       "   \"dropout\": 0.1,\n",
       "   \"end_n_top\": 5,\n",
       "   \"eos_token_id\": 2,\n",
       "   \"ff_activation\": \"gelu\",\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"layer_norm_eps\": 1e-12,\n",
       "   \"mem_len\": null,\n",
       "   \"model_type\": \"xlnet\",\n",
       "   \"n_head\": 12,\n",
       "   \"n_layer\": 12,\n",
       "   \"pad_token_id\": 5,\n",
       "   \"reuse_len\": null,\n",
       "   \"same_length\": false,\n",
       "   \"start_n_top\": 5,\n",
       "   \"summary_activation\": \"tanh\",\n",
       "   \"summary_last_dropout\": 0.1,\n",
       "   \"summary_type\": \"last\",\n",
       "   \"summary_use_proj\": true,\n",
       "   \"task_specific_params\": {\n",
       "     \"text-generation\": {\n",
       "       \"do_sample\": true,\n",
       "       \"max_length\": 250\n",
       "     }\n",
       "   },\n",
       "   \"untie_r\": true,\n",
       "   \"vocab_size\": 32000\n",
       " },\n",
       " 'attn_type': 'bi',\n",
       " 'same_length': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_xlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters BERT 108.340804\n",
      "Number of tokens in vocabulary BERT 28996\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model_bert = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "print(\"Number of parameters BERT\", get_n_params(model_bert)/1e6)\n",
    "print(\"Number of tokens in vocabulary BERT\", len(tokenizer_bert.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at wietsedv/bert-base-dutch-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters Dutch BERTje 109112880\n",
      "Number of tokens in vocabulary Dutch BERTje 30000\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer_bert_dutch = AutoTokenizer.from_pretrained(\"wietsedv/bert-base-dutch-cased\")\n",
    "model_bert_dutch = AutoModelForMaskedLM.from_pretrained(\"wietsedv/bert-base-dutch-cased\")\n",
    "\n",
    "print(\"Number of parameters Dutch BERTje\", get_n_params(model_bert_dutch))\n",
    "print(\"Number of tokens in vocabulary Dutch BERTje\", len(tokenizer_bert_dutch.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters RobBERT 116752130\n",
      "Number of tokens in vocabulary RobBERT 39982\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "tokenizer_robbert = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model_robbert = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "\n",
    "print(\"Number of parameters RobBERT\", get_n_params(model_robbert))\n",
    "print(\"Number of tokens in vocabulary RobBERT\", len(tokenizer_robbert.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters RoBERTa 124.645632\n",
      "Number of tokens in vocabulary RoBERTa 50265\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model_roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "print(\"Number of parameters RoBERTa\", get_n_params(model_roberta)/1e6)\n",
    "print(\"Number of tokens in vocabulary RoBERTa\", len(tokenizer_roberta.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "# Initializing a RoBERTa configuration\n",
    "configuration = RobertaConfig()\n",
    "# Initializing a model from the configuration\n",
    "model = RobertaModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:16:36.839262 4676832704 filelock.py:274] Lock 140728025270256 acquired on /Users/claartje/.cache/torch/transformers/ee421a5bf82f3951a3dc15afe28cfc38fa559efa382304516ffa6ed293ab83e9.b479b28114c95b1bad59f014bb119d3a50b3c5e5c87d6b0e0090a60c36629a83.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4f4eaff5234a1b9160e5c7f10fd9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:16:37.353291 4676832704 filelock.py:318] Lock 140728025270256 released on /Users/claartje/.cache/torch/transformers/ee421a5bf82f3951a3dc15afe28cfc38fa559efa382304516ffa6ed293ab83e9.b479b28114c95b1bad59f014bb119d3a50b3c5e5c87d6b0e0090a60c36629a83.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:16:37.760485 4676832704 filelock.py:274] Lock 140728024977248 acquired on /Users/claartje/.cache/torch/transformers/91ff5e1b255f639e7da51ea8c6a52a43f727a92c6b663da5e6191631dae60c53.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c95917c94404bd5b6129ebbe86a0534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=5069051.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:16:39.275153 4676832704 filelock.py:318] Lock 140728024977248 released on /Users/claartje/.cache/torch/transformers/91ff5e1b255f639e7da51ea8c6a52a43f727a92c6b663da5e6191631dae60c53.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:16:41.053649 4676832704 filelock.py:274] Lock 140728025270032 acquired on /Users/claartje/.cache/torch/transformers/609796900634a6be6fe33dcf4a637ab799fafe01b65b4d5682690d58995ada39.c7e58d3598471b931c8c2d436201b40863e68677eb231675c2264d6a82b2e7bb.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94284550324546e0b3bc2b57bece5dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2239696720.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 13:18:29.650166 4676832704 filelock.py:318] Lock 140728025270032 released on /Users/claartje/.cache/torch/transformers/609796900634a6be6fe33dcf4a637ab799fafe01b65b4d5682690d58995ada39.c7e58d3598471b931c8c2d436201b40863e68677eb231675c2264d6a82b2e7bb.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large-finetuned-conll02-dutch were not used when initializing XLMRobertaForMaskedLM: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForMaskedLM were not initialized from the model checkpoint at xlm-roberta-large-finetuned-conll02-dutch and are newly initialized: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters Dutch XLM-RoBERTa 560.142482\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XLMRobertaTokenizer' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d30bf57eac7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of parameters Dutch XLM-RoBERTa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_n_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xlm_roberta_dutch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of tokens in vocabulary Dutch XLM-RoBERTa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_xlm_roberta_dutch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'XLMRobertaTokenizer' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer_xlm_roberta_dutch = AutoTokenizer.from_pretrained(\"xlm-roberta-large-finetuned-conll02-dutch\")\n",
    "model_xlm_roberta_dutch = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large-finetuned-conll02-dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters Dutch XLM-RoBERTa 560.142482\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters Dutch XLM-RoBERTa\", get_n_params(model_xlm_roberta_dutch)/1e6)\n",
    "# print(\"Number of tokens in vocabulary Dutch XLM-RoBERTa\", len(tokenizer_xlm_roberta_dutch.encoder.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TransfoXLConfig, TransfoXLModel\n",
    "\n",
    "# Initializing a Transformer XL configuration\n",
    "configuration = TransfoXLConfig()\n",
    "# Initializing a model from the configuration\n",
    "model = TransfoXLModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283.885936"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N params: 283.885936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransfoXLModel(\n",
       "  (word_emb): AdaptiveEmbedding(\n",
       "    (emb_layers): ModuleList(\n",
       "      (0): Embedding(20000, 1024)\n",
       "      (1): Embedding(20000, 256)\n",
       "      (2): Embedding(160000, 64)\n",
       "      (3): Embedding(67735, 16)\n",
       "    )\n",
       "    (emb_projs): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 1024x1024]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 1024x256]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 1024x64]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 1024x16]\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (5): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (6): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (7): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (8): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (9): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (10): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (11): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (12): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (13): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (14): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (15): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (16): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (17): RelPartialLearnableDecoderLayer(\n",
       "      (dec_attn): RelPartialLearnableMultiHeadAttn(\n",
       "        (qkv_net): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (dropatt): Dropout(p=0.0, inplace=False)\n",
       "        (o_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (r_net): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (pos_ff): PositionwiseFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pos_emb): PositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"N params:\", get_n_params(model) /  1e6)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.75008\n"
     ]
    }
   ],
   "source": [
    "print(232750080/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Sony PlayStation gamers are being advised to stay away from the network because of a problem with the PlayStation 3 network.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_bbc\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/roberta2roberta_L-24_bbc\")\n",
    "\n",
    "article = \"\"\"The problem is affecting people using the older\n",
    "versions of the PlayStation 3, called the \"Fat\"\n",
    "model.The problem isn't affecting the newer PS3\n",
    "Slim systems that have been on sale since\n",
    "September last year.Sony have also said they are\n",
    "aiming to have the problem fixed shortly but is\n",
    "advising some users to avoid using their console\n",
    "for the time being.\"We hope to resolve this\n",
    "problem within the next 24 hours,\" a statement\n",
    "reads. \"In the meantime, if you have a model other\n",
    "than the new slim PS3, we advise that you do not\n",
    "use your PS3 system, as doing so may result in\n",
    "errors in some functionality, such as recording\n",
    "obtained trophies, and not being able to restore\n",
    "certain data.\"We believe we have identified that\n",
    "this problem is being caused by a bug in the clock\n",
    "functionality incorporated in the system.\"The\n",
    "PlayStation Network is used by millions of people\n",
    "around the world.It allows users to play their\n",
    "friends at games like Fifa over the internet and\n",
    "also do things like download software or visit\n",
    "online stores.\"\"\"\n",
    "\n",
    "input_ids = tokenizer(article, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "\n",
    "print(tokenizer.decode(output_ids, skip_special_tokens=True))\n",
    "# should output\n",
    "# Some Sony PlayStation gamers are being advised to stay away from the network because of a problem with the PlayStation 3 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455.263414"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3961f17a194d2ebe4900313da2daa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=3435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc2f9b121b04cb9b34c3fb1334fa652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=845717.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34099920c51402a8e2fa9c05fd6ece1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1821418078.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fox is developing a two-hour remake of the 1975 cult classic. The special will be directed, executive-produced and choreographed by Kenneth Ortega. The special is timed to celebrate the 40th anniversary of the film, which has grossed more than $112 million.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_cnn_daily_mail\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/roberta2roberta_L-24_cnn_daily_mail\")\n",
    "\n",
    "article = \"\"\"    (The Hollywood Reporter)\"The Rocky Horror Picture\n",
    "Show\" is the latest musical getting the small-\n",
    "screen treatment. Fox is developing a two-hour\n",
    "remake of the 1975 cult classic to be directed,\n",
    "executive-produced and choreographed by Kenneth\n",
    "Ortega (\"High School Musical\"). The project,\n",
    "tentatively titled \"The Rocky Horror Picture Show\n",
    "Event,\" is casting-contingent. The special will be\n",
    "filmed in advance and not air live, but few\n",
    "details beyond that are known. In addition to\n",
    "Ortega, Gail Berman and Lou Adler, who produced\n",
    "the original film, are also attached as executive\n",
    "producers. The special will be produced by Fox 21\n",
    "Television Studios, and Berman's The Jackal Group.\n",
    "The special is timed to celebrate the 40th\n",
    "anniversary of the film, which has grossed more\n",
    "than $112 million and still plays in theaters\n",
    "across the country. TV premiere dates: The\n",
    "complete guide . This isn't the first stab at\n",
    "adapting \"The Rocky Horror Picture Show.\" In 2002,\n",
    "Fox unveiled plans for an adaptation timed to the\n",
    "30th anniversary that never came to fruition. The\n",
    "faces of pilot season 2015 . Fox's \"Glee\" covered\n",
    "several of the show's most popular songs for a\n",
    "Season 2 episode and even released a special \"The\n",
    "Rocky Horror Glee Show\" EP. There is no plan yet\n",
    "for when the adaptation will air. Fox also has a\n",
    "live musical production of \"Grease\", starring\n",
    "Julianne Hough and Vanessa Hudgens, scheduled to\n",
    "air on Jan. 31, 2016. Broadcast TV scorecard .\n",
    "Following in the footsteps of \"The Sound of Music\"\n",
    "and \"Peter Pan,\" NBC recently announced plans to\n",
    "air a live version of The Wiz later this year.\n",
    "Ortega's credits include \"Gilmore Girls,\" \"This Is\n",
    "It\" and \"Hocus Pocus.\" He is repped by Paradigm\n",
    "and Hanson, Jacobson. 2015 The Hollywood\n",
    "Reporter. All rights reserved.\"\"\"\n",
    "\n",
    "input_ids = tokenizer(article, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "print(tokenizer.decode(output_ids, skip_special_tokens=True))\n",
    "# should output\n",
    "# Fox is developing a two-hour remake of the 1975 cult classic. The special will be directed, executive-produced and choreographed by Kenneth Ortega. \n",
    "# The special is timed to celebrate the 40th anniversary of the film, which has grossed more than $112 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/claartje/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "standard_bert = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
    "# standard_gpt2 = torch.hub.load('huggingface/pytorch-transformers', 'model', 'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.310272\n"
     ]
    }
   ],
   "source": [
    "print(get_n_params(standard_bert)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/claartje/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "standard_roberta = torch.hub.load('huggingface/pytorch-transformers', 'model', 'roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.645632\n"
     ]
    }
   ],
   "source": [
    "print(get_n_params(standard_roberta)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ccd3541ef34c16b733bb20bda9998a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9a2d99f2234eeb965f00cf7c79a165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7625f1533774fb1b59f2f5af1e9759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=263273408.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "65.190912\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "print(get_n_params(model)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due Due hurricane, Lobsterfest has been canceled, making Bob very happy about it.<::::> He decides to open Bob's Burgers for customers who were planning on going to Lobsterfest.com.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_wikisplit\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/roberta2roberta_L-24_wikisplit\")\n",
    "\n",
    "long_sentence = \"\"\"Due to the hurricane, Lobsterfest has been canceled, making Bob very happy about it and he decides to open Bob 's Burgers for customers who were planning on going to Lobsterfest.\"\"\"\n",
    "\n",
    "input_ids = tokenizer(long_sentence, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "print(tokenizer.decode(output_ids, skip_special_tokens=False))\n",
    "# should output\n",
    "# Due Due hurricane, Lobsterfest has been canceled, making Bob very happy about it. He decides to open B\n",
    "# ob's Burgers for customers who were planning on going to Lobsterfest.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
